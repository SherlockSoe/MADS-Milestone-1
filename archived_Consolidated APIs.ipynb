{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>SIADS 591/592</center>\n",
    "# <center>Milestone I Project Report</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Project Title:</b>\n",
    "#### Understanding demographic dynamics of high school aged students in the United States\n",
    "\n",
    "#### <b>Team members:</b>\n",
    "- Leonardo Cedeno (lcedeno)\n",
    "- Yin-Chen Hsu (yinchenh)\n",
    "\n",
    "#### <b>Motivation:</b>\n",
    "##### The main motivation for this project was the need of higher-education institutions to have a database with granulary demographic information to use in their recruitment strategies in the context of increasing student diversity, supporting student academic success and meeting financial stewardship goals. We believe that one of the foundations of a strong egalitarian society is to promote access to quality education for students of all races and particularly to recruit minority students that may otherwise not apply or enroll in college.\n",
    "##### Our goal is to curate a collection of tables and visualizations that can help college and university recruiters be more effective in implementing a recruitment strategy that focuses on meeting a very inclusive diversity agenda.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Acquiring Data</b>\n",
    "##### Since each one of the 2 main datasets, Census and CRCD, came from different sources and had different variables, we decided to explore the nuances of acquiring data separately.\n",
    "\n",
    "##### <b>Census Data</b>\n",
    "##### CensusData is a Python library that supports accessing the official US Census Bureau’s API. It can be downloaded from the following link: https://pypi.org/project/CensusData/, it supports pulling data  from the American Community Survey series. We decided to use the 5 year estimates from 2015 through 2019.\n",
    "\n",
    "##### The CensusData library supports download of detailed demographic and geographic data and to align with our research objectives we chose the following variables by zip code for the entire nation: \n",
    "- Number of teens ages 15 to 17 by gender and race\n",
    "- Number of households with incomes between $150k to $220k and above $220k by zip code for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import censusdata, pandas as pd\n",
    "\n",
    "def import_censusdata0(year, variables, geo_agg):\n",
    "    census_data = censusdata.download('acs5', year, \n",
    "                                censusdata.censusgeo([('state','*'), geo_agg]), variables)\n",
    "\n",
    "    dictionary = {'B02001_001E': 'Total Pop Estimate '+str(year), 'B19001_001E':'HHI', 'B19001_016E':'HHI 150K-200K','B19001A_001E':'HHI 220K+',\\\n",
    "    'B01001_006E':'Males 15-17', 'B01001A_006E':'White Males 15-17','B01001B_006E':'Black Males 15-17', 'B01001I_006E':'Hispanic Males 15-17',\\\n",
    "    'B01001_030E': 'Females 15-17', 'B01001A_021E':'White Females 15-17',' B01001B_021E':'Black Females 15-17','B01001I_021E': 'Hispanic Females 15-17'}\n",
    "    \n",
    "    census_data.rename(columns =dictionary, inplace=True)\n",
    "    for index, data in census_data.iterrows():\n",
    "        census_data.loc[index,'County'], census_data.loc[index,'State']= index.name, index.params()[0][1]\n",
    "\n",
    "    #census_data.reset_index(drop=True,inplace=True)\n",
    "    census_dataframe = pd.DataFrame(census_data)\n",
    "\n",
    "    return census_dataframe#.groupby(['State', 'County']).agg({'Total Pop Estimate'+str(year):'sum',\n",
    "                                                           #     'Males 15-17':'sum', 'Black Males 15-17':'sum', 'Hispanic Males 15-17':'sum',\\\n",
    "                                                           # 'HHI 220K+':'sum'})\n",
    "\n",
    "male_vars = ['B02001_001E', 'B01001_006E','B01001A_006E','B01001_006E' , 'B01001B_006E', 'B01001I_006E',\\\n",
    "                                                'B19001_001E', 'B19001_016E','B19001A_001E']\n",
    "\n",
    "female_vars = ['B02001_001E', 'B01001_030E', 'B01001A_021E','B01001B_021E','B01001I_021E']\n",
    "\n",
    "males_census_2019df = import_censusdata0(2019, male_vars, ('county', '*') )\n",
    "males_census_2018df = import_censusdata0(2018, male_vars, ('county', '*') )\n",
    "\n",
    "growth_trend = pd.concat([males_census_2019df['Total Pop Estimate 2019'], males_census_2018df['Total Pop Estimate 2018']], axis=1)\n",
    "growth_trend['% delta'] = growth_trend['Total Pop Estimate 2019'] / growth_trend['Total Pop Estimate 2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this variant uses groupings for the variables\n",
    "import requests\n",
    " \n",
    "class census_api:\n",
    "    baseurl = \"https://api.census.gov/data/2019/acs/acs5?get=NAME,group(B02001)&for=zip%20code%20tabulation%20area:*&in=state:*\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        #self.paramx = {'dataset'}\n",
    "        self.resp = requests.get(self.baseurl).json()\n",
    "         \n",
    "    def output(self):\n",
    "        return self.resp\n",
    "census_header = census_api().output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b>CRCD Data</b>\n",
    "##### The federal government releases large amounts of data on U.S. schools every year. But this information is scattered across multiple datasets that are often difficult to access. Urban Institute’s Education Data Portal (URL: https://educationdata.urban.org/documentation/) offers an application programming interface (API) for users to assess data in a single portal. All data are returned in JSON format and viewed directly in a web browser by hitting a URL endpoint.\n",
    "\n",
    "##### To make a specific API call, we need to add modifiers for the  URL, including source, endpoint, year, other specifiers, and filters. The URL follows this format:\n",
    "<blockquote>https://educationdata.urban.org/api/v1/{topic}/{source}/{endpoint}/{year}/[additional_specifiers _or_disaggregators]/[optional filters]</blockquote>\n",
    "\n",
    "##### To align with our research goal, we get the data with specified conditions:\n",
    "- Directory of high schools (source: CDC)\n",
    "- Enrollment data of high schools (source: CDC)\n",
    "- Enrollment data by grade of high schools (source: CRDC)\n",
    "- SAT and ACT participation record (source: CRDC)\n",
    "- Retention record by grade of high schools (source: CRDC)\n",
    "- Finance data of high schools (source: CRDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def school_data(year, dataset, var, grade, fips):\n",
    "    import urllib, json, pandas as pd\n",
    "    base_url = \"https://educationdata.urban.org/api/v1/schools/\"\n",
    "    if (dataset, var) in {('ccd', 'directory'), ('crdc', 'directory'), ('crdc', 'school-finance')}:\n",
    "         url = base_url+dataset+\"/\"+var+\"/\"+str(year)+\"/?fips=\"+str(fips)\n",
    "    elif (dataset, var) in {('ccd', 'enrollment'), ('crdc', 'retention')}:\n",
    "         url = base_url+dataset+\"/\"+var+\"/\"+str(year)+\"/\"+str(grade)+\"/race/sex/?fips=\"+str(fips)\n",
    "    elif (dataset, var) in {('crdc', 'enrollment'), ('crdc', 'sat-act-participation')}:\n",
    "         url = base_url+dataset+\"/\"+var+\"/\"+str(year)+\"/race/sex/?fips=\"+str(fips)\n",
    "\n",
    "    print(url)\n",
    "    df_lst = []\n",
    "    while True:\n",
    "         try:\n",
    "               response = urllib.request.urlopen(url)\n",
    "               retention = json.loads(response.read())\n",
    "               df = pd.json_normalize(retention, record_path= ['results'])\n",
    "               if response.getcode() == 200:\n",
    "                   break\n",
    "         except Exception as inst:\n",
    "               print (inst)\n",
    "    df_lst.append(df)\n",
    "    while retention['next'] != None:\n",
    "         url = retention['next']\n",
    "         print(url)\n",
    "         while True:\n",
    "               try:\n",
    "                    response = urllib.request.urlopen(url)\n",
    "                    retention = json.loads(response.read())\n",
    "                    df = pd.json_normalize(retention, record_path= ['results'])\n",
    "                    if response.getcode() == 200:\n",
    "                         break\n",
    "               except Exception as inst:\n",
    "                    print (inst)\n",
    "         df_lst.append(df)\n",
    "    return pd.concat(df_lst)\n",
    "# school_data(2015, 'ccd', 'enrollment', 'grade-12', 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ccd_multiple(lst, var, grade, fips):\n",
    "    df_loop=[]\n",
    "    for y in lst:\n",
    "        d = school_data(y, 'ccd', var, grade, fips)\n",
    "        df_loop.append(d)\n",
    "    return df_loop\n",
    "years = [2015, 2016, 2017, 2018, 2019]\n",
    "# dfs_ccd_directory = get_ccd_multiple(years, 'directory', False, 45)\n",
    "# dfs_ccd_enrollment = get_ccd_multiple(years, 'enrollment', 'grade-12', 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The crdc enrollment data is published biennially!!! (The most recent years are 2013, 2015 and 2017)\n",
    "def get_crdc_multiple(lst, var, grade, fips):\n",
    "    df_loop=[]\n",
    "    for y in lst:\n",
    "        d = school_data(y, 'crdc', var, grade, fips)\n",
    "        df_loop.append(d)\n",
    "    return df_loop\n",
    "years = [2013, 2015, 2017]\n",
    "# dfs_crdc_directory = get_crdc_multiple(years, 'directory', False, 45)\n",
    "# dfs_crdc_enrollment = get_crdc_multiple(years, 'enrollment', 'grade-12', 45)\n",
    "# dfs_crdc_sat_act_part = get_crdc_multiple(years, 'sat-act-participation', 'grade-12', 45)\n",
    "# dfs_school_finance = get_crdc_multiple(years, 'school-finance', False, 45)\n",
    "# dfs_retention = get_crdc_multiple(years, 'retention', 'grade-12', 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### In summary, acquiring the data for this project was a mixed bag of convenience and learning from scratch. Using the CensusData Python library was very convenient and it sped up the process dramatically. On the other hand, the US Department of Education data was a challenge that involved writing an API wrapper, which led to high volume files (total of 331 megabytes for all years)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <b>Pre-processing data</b>\n",
    "##### Once the data was downloaded using APIs as described above we decided that it was best to create a PostgreSQL database  to lower our reliance on Python in-memory calculations. Originally the PostgreSQL database was developed locally in Leo’s machine and then migrated to an Azure database server. This step was crucial in allowing both team members to continue to work on a consolidated datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "957b2560371b1c7d801a409fa89b68f929b3932dd6ae0e3851e23e61fd4ebe9e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
